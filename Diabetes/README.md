“A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.” To find that logic is called “machine learning”.\
**Tom  Mitchell**

##### Types of Machine learning Algorithms
1- *Supervised Learning*: Input data(training data) and has a  label or result . ex: Spam/not-spam  (stock price)\
2- *Unsupervised Learning*: Input data is not labeled and does not have a known result. ex: Grouping students  by marks\
3- *Semi-Supervised Learning*: Input data is a mixture of labeled and unlabeled examples. ex: a photo archive where only some of the images are labeled, (e.g. dog, cat, person) and the majority are unlabeled.\
4- *Reinforcement Learning*: A goal-oriented learning based on interaction with environment. Autonomous cars.

  
###### Supervised Machine Learning
- Regression: Linear Regression, Logistic Regression
- Instance-based Algorithms: k-Nearest Neighbor (KNN)
- Decision Tree Algorithms: CART
- Bayesian Algorithms: Naive Bayes
- Ensemble Algorithms: eXtreme Gradient Boosting
- Deep Learning Algorithms: Convolution Neural Network

###### Classification vs Regression
Classification predicting a label 
Regression predicting a quantity.

###### Classification Algorithms Examples:
Linear: Linear Regression, Logistic Regression
Nonlinear: Trees, k-Nearest Neighbors
Ensemble:
Bagging: Random Forest
Boosting: AdaBoost
Machine Learning Pipeline:
Define Problem


###### Data Visualization methods 
Data Selection
Feature Selection methods ..
Feature Engineering methods ..
Data Transormation methods ..
Spot Check Algorithm




###### The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting
- Correcting abnormal values and outliers  (age = 800 instead of 80)
- Completing missing information  (null) use  mean, median
- Creating new features for analysis  ( use existing features to create new features)
- Converting fields to the correct format for calculations 
 
 <p></p>
 
- Loading Dataset
- Information About Dataset columns and Summary
- Cleaning Data Eliminate Null values and zeros, Drop dublicates
- Data visualize  to see if data is balanced understand the reltionship between variables 
- Count Plot :- to see if the dataset is balanced or not
- Histograms :- to see if data is normally distributed or skewed
- Box Plot :- to analyse the distribution and see the outliers
- Scatter plots :- to understand relationship between any two variables
- Pair plot :- to create scatter plot between all the variables

* Feature Selection
* Handling Outliers
* Split the Data Frame into X and y
* TRAIN TEST SPLIT
* Build the Classification Algorithm

- KNN
- Naive Bayes
- SVM
- Decision Tree
- Random Forest
- Logistic Regression
- Hyper Parameter Tuning using GridSearch CV
- Fit Best Model
- Predict on testing data using that model
- Performance Metrics :- Confusion Matrix, F1 Score, Precision Score, Recall Score


###### Outliers
Data Entry Errors,Data Entry Errors,Measurement Error,Natural Outlier. 
- Using Z score method (Find out how many standard deviations value away from the mean)
- ROBUST Z-SCORE (Called as Median absolute deviation method. It is similar to Z-score method with some changes in parameters)

 
 
 
 
 
